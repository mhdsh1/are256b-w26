{smcl}
{com}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\Users\mshams\Dropbox\Courses\are256b-w26\week2.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}15 Jan 2026, 16:51:43
{txt}
{com}. *--------------------------------------------------
. 
. *open a .dta (Stata) file
. *we use clear to reaplce the new dataset with the former one
. use "data\EAWE01.dta", clear 
{txt}
{com}. 
. *----------------------------------------------------------------------------*
. * section 1: linear model
. *----------------------------------------------------------------------------*
. 
. *let us work with some linear probability models
. *P(Y_i=1|X_i) = \beta X_i + \epsilon_i 
. *Prob of finishing a bachelor's degree vs composite cognitive ability test
. 
. reg EDUCBA  ASVABC, robust

{txt}Linear regression                               Number of obs     = {res}       500
                                                {txt}F(1, 498)         =  {res}    87.02
                                                {txt}Prob > F          = {res}    0.0000
                                                {txt}R-squared         = {res}    0.1185
                                                {txt}Root MSE          =    {res} .42946

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      EDUCBA{col 14}{c |} Coefficient{col 26}  std. err.{col 38}      t{col 46}   P>|t|{col 54}     [95% con{col 67}f. interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}ASVABC {c |}{col 14}{res}{space 2} .1746469{col 26}{space 2} .0187219{col 37}{space 1}    9.33{col 46}{space 3}0.000{col 54}{space 4} .1378633{col 67}{space 3} .2114305
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .2566462{col 26}{space 2}  .017902{col 37}{space 1}   14.34{col 46}{space 3}0.000{col 54}{space 4} .2214734{col 67}{space 3}  .291819
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{com}. 
. * calcualting the \hat{c -(}Y{c )-}_i = \hat{c -(}\beta{c )-}X_i for some values of X_i
. 
. sum ASVABC, detail

                           {txt}ASVABC
{hline 61}
      Percentiles      Smallest
 1%    {res}-2.218827      -3.053471
{txt} 5%    {res}-1.464511      -2.505618
{txt}10%    {res}-.9897522      -2.462728       {txt}Obs         {res}        500
{txt}25%    {res}-.2895314      -2.348369       {txt}Sum of wgt. {res}        500

{txt}50%    {res}  .334199                      {txt}Mean          {res} .2253335
                        {txt}Largest       Std. dev.     {res} .9005283
{txt}75%    {res} .8584125       2.000001
{txt}90%    {res} 1.320404       2.003199       {txt}Variance      {res} .8109511
{txt}95%    {res} 1.619688       2.049761       {txt}Skewness      {res}-.4774249
{txt}99%    {res} 1.971871       2.319522       {txt}Kurtosis      {res} 3.170781
{txt}
{com}. 
. display 0.2566+0.1746*0.3341
{res}.31493386
{txt}
{com}. display 0.2566+0.1746*1.9718
{res}.60087628
{txt}
{com}. display 0.2566+0.1746*(-2.2188)
{res}-.13080248
{txt}
{com}. 
. * alternative way to calculate the predicted probability
. display _b[_cons]+_b[ASVABC]*0.3341
{res}.31499574
{txt}
{com}. display _b[_cons]+_b[ASVABC]*1.9718
{res}.60101499
{txt}
{com}. display _b[_cons]+_b[ASVABC]*(-2.2188)
{res}-.13086036
{txt}
{com}. 
. *Does the last predicted probability make sense? 
. * No, it yields a negative probability
. 
. *let's find the fitted values for all the observations
. *\hat{c -(}Y{c )-}_i = \hat{c -(}\beta{c )-}X_i
. *command predict yields the fitted values for all the observations 
. * based on the "latest" model ran 
. help predict // like ? predict in R
{txt}
{com}. predict EDUCBA_hat, xb  
{txt}
{com}. 
. browse EDUCBA EDUCBA_hat
{txt}
{com}. 
. count if EDUCBA_hat>1
  {res}0
{txt}
{com}. count if EDUCBA_hat<0
  {res}24
{txt}
{com}. count if missing(EDUCBA_hat)
  {res}0
{txt}
{com}. 
. *Show the predicted probability graphically
. twoway scatter EDUCBA_hat ASVABC
{res}{txt}
{com}. graph export out/linear.png, replace
{txt}{p 0 4 2}
file {bf}
out/linear.png{rm}
saved as
PNG
format
{p_end}

{com}. 
. *----------------------------------------------------------------------------*
. * sction 2: nonlinear model
. *----------------------------------------------------------------------------*
. 
. *let us move to non-linear probability models
. *Non-linear probability models map the dependent variables using a function
. *whose range lies between zero and one.
. 
. *PROBIT: The function used for mapping is the cumulative distribution
. *of a normal.
. *P(Y_i=1|X_i) = \Phi(\beta X_i + \epsilon_i) 
. 
. probit EDUCBA  ASVABC, robust 

{res}{txt}Iteration 0:{space 2}Log pseudolikelihood = {res:-303.71846}  
Iteration 1:{space 2}Log pseudolikelihood = {res:-270.33421}  
Iteration 2:{space 2}Log pseudolikelihood = {res:-269.96199}  
Iteration 3:{space 2}Log pseudolikelihood = {res:-269.96172}  
Iteration 4:{space 2}Log pseudolikelihood = {res:-269.96172}  
{res}
{txt}{col 1}Probit regression{col 57}{lalign 13:Number of obs}{col 70} = {res}{ralign 6:500}
{txt}{col 57}{lalign 13:Wald chi2({res:1})}{col 70} = {res}{ralign 6:59.05}
{txt}{col 57}{lalign 13:Prob > chi2}{col 70} = {res}{ralign 6:0.0000}
{txt}{col 1}{lalign 20:Log pseudolikelihood}{col 21} = {res}{ralign 10:-269.96172}{txt}{col 57}{lalign 13:Pseudo R2}{col 70} = {res}{ralign 6:0.1111}

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      EDUCBA{col 14}{c |} Coefficient{col 26}  std. err.{col 38}      z{col 46}   P>|z|{col 54}     [95% con{col 67}f. interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}ASVABC {c |}{col 14}{res}{space 2} .6190642{col 26}{space 2} .0805616{col 37}{space 1}    7.68{col 46}{space 3}0.000{col 54}{space 4} .4611664{col 67}{space 3} .7769619
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-.7621472{col 26}{space 2} .0707757{col 37}{space 1}  -10.77{col 46}{space 3}0.000{col 54}{space 4}-.9008652{col 67}{space 3}-.6234293
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}

{com}. *Compare results with Linear Probability Model
. 
. 
. *Predict Probability
. *\hat{c -(}Y{c )-}_i = \Phi{c -(}\hat{c -(}\beta{c )-}X_i{c )-}
. 
. *calculating the predicted probability
. h nlcom
{txt}
{com}. h norm
{txt}
{com}. *At 75 percentile
. nlcom norm(_b[ASVABC]*0.8584 + _b[ _cons])

       {txt}_nl_1: {res}norm(_b[ASVABC]*0.8584 + _b[ _cons])

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}      EDUCBA{col 14}{c |} Coefficient{col 26}  Std. err.{col 38}      z{col 46}   P>|z|{col 54}     [95% con{col 67}f. interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}_nl_1 {c |}{col 14}{res}{space 2} .4087574{col 26}{space 2} .0278879{col 37}{space 1}   14.66{col 46}{space 3}0.000{col 54}{space 4} .3540982{col 67}{space 3} .4634166
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}

{com}. *At 1 percentile
. nlcom norm(_b[ASVABC]*-2.2188 + _b[ _cons])

       {txt}_nl_1: {res}norm(_b[ASVABC]*-2.2188 + _b[ _cons])

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}      EDUCBA{col 14}{c |} Coefficient{col 26}  Std. err.{col 38}      z{col 46}   P>|z|{col 54}     [95% con{col 67}f. interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}_nl_1 {c |}{col 14}{res}{space 2} .0163508{col 26}{space 2} .0090219{col 37}{space 1}    1.81{col 46}{space 3}0.070{col 54}{space 4}-.0013318{col 67}{space 3} .0340335
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}

{com}. 
. *Generate variable that predicts for every observation
. predict EDUCBA_probit_hat
{txt}(option {bf:pr} assumed; Pr(EDUCBA))

{com}. browse EDUCBA EDUCBA_hat EDUCBA_probit_hat
{txt}
{com}. twoway (scatter EDUCBA_probit_hat ASVABC)
{res}{txt}
{com}. 
. 
. *----------------------------------------------------------------------------*
. * section 3: computing marginal effects 
. *----------------------------------------------------------------------------*
. 
. *Computing marginal effects
. *Look at Slides 68-69 for definitions
. 
. *Average Margnal Effect
. margins, dydx(ASVABC)
{res}
{txt}{col 1}Average marginal effects{col 60}{lalign 13:Number of obs}{col 73} = {res}{ralign 3:500}
{txt}{col 1}Model VCE: {res:Robust}

{txt}{p2colset 1 13 13 2}{...}
{p2col:Expression:}{res:Pr(EDUCBA), predict()}{p_end}
{p2col:dy/dx wrt:}{res:ASVABC}{p_end}
{p2colreset}{...}

{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26} Delta-method
{col 14}{c |}      dy/dx{col 26}   std. err.{col 38}      z{col 46}   P>|z|{col 54}     [95% con{col 67}f. interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}ASVABC {c |}{col 14}{res}{space 2} .1888049{col 26}{space 2} .0206424{col 37}{space 1}    9.15{col 46}{space 3}0.000{col 54}{space 4} .1483465{col 67}{space 3} .2292632
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{com}. 
. *Marginal effects evaluated at the mean 
. margins, dydx(ASVABC) atmeans
{res}
{txt}{col 1}Conditional marginal effects{col 60}{lalign 13:Number of obs}{col 73} = {res}{ralign 3:500}
{txt}{col 1}Model VCE: {res:Robust}

{txt}{p2colset 1 13 13 2}{...}
{p2col:Expression:}{res:Pr(EDUCBA), predict()}{p_end}
{p2col:dy/dx wrt:}{res:ASVABC}{p_end}
{p2colreset}{...}
{lalign 4:At: }{space 0}{lalign 6:ASVABC} = {res:{ralign 8:.2253335}} {txt:(mean)}

{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26} Delta-method
{col 14}{c |}      dy/dx{col 26}   std. err.{col 38}      z{col 46}   P>|z|{col 54}     [95% con{col 67}f. interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}ASVABC {c |}{col 14}{res}{space 2} .2034506{col 26}{space 2} .0257674{col 37}{space 1}    7.90{col 46}{space 3}0.000{col 54}{space 4} .1529474{col 67}{space 3} .2539537
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{com}. // alternative: mfx compute, dydx
. 
. * for an individual with mean cognitive score, if you increase the coginitive score 
. * by 1% the probablity of getting degree will increase by 0.2% 
. 
. 
. *Marginal effects evaluated at a different point
. margins, dydx(ASVABC) at(ASVABC=0.1)
{res}
{txt}{col 1}Conditional marginal effects{col 60}{lalign 13:Number of obs}{col 73} = {res}{ralign 3:500}
{txt}{col 1}Model VCE: {res:Robust}

{txt}{p2colset 1 13 13 2}{...}
{p2col:Expression:}{res:Pr(EDUCBA), predict()}{p_end}
{p2col:dy/dx wrt:}{res:ASVABC}{p_end}
{p2colreset}{...}
{lalign 4:At: }{space 0}{lalign 6:ASVABC} = {res:{ralign 2:.1}}

{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26} Delta-method
{col 14}{c |}      dy/dx{col 26}   std. err.{col 38}      z{col 46}   P>|z|{col 54}     [95% con{col 67}f. interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}ASVABC {c |}{col 14}{res}{space 2} .1932726{col 26}{space 2} .0232853{col 37}{space 1}    8.30{col 46}{space 3}0.000{col 54}{space 4} .1476342{col 67}{space 3} .2389111
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{com}. margins, dydx(ASVABC) at(ASVABC=0.6)
{res}
{txt}{col 1}Conditional marginal effects{col 60}{lalign 13:Number of obs}{col 73} = {res}{ralign 3:500}
{txt}{col 1}Model VCE: {res:Robust}

{txt}{p2colset 1 13 13 2}{...}
{p2col:Expression:}{res:Pr(EDUCBA), predict()}{p_end}
{p2col:dy/dx wrt:}{res:ASVABC}{p_end}
{p2colreset}{...}
{lalign 4:At: }{space 0}{lalign 6:ASVABC} = {res:{ralign 2:.6}}

{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26} Delta-method
{col 14}{c |}      dy/dx{col 26}   std. err.{col 38}      z{col 46}   P>|z|{col 54}     [95% con{col 67}f. interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}ASVABC {c |}{col 14}{res}{space 2} .2288218{col 26}{space 2} .0315965{col 37}{space 1}    7.24{col 46}{space 3}0.000{col 54}{space 4} .1668938{col 67}{space 3} .2907499
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{com}. 
. 
. // what does margins alone do?
. 
. *----------------------------------------------------------------------------*
. * section 4: model comparison based on rmse 
. *----------------------------------------------------------------------------*
. 
. *How do the models compare? (linear vs probit)
. twoway (scatter EDUCBA_probit_hat ASVABC) ///
>        (scatter EDUCBA_hat ASVABC) ///
>        (scatter EDUCBA ASVABC)
{res}{txt}
{com}. 
. *We use root mean squared error (rmse) concept to compare 
. *rmse = sqrt{c -(}((1/n)*(\Sigma{c -(}(Y_i - \hat{c -(}Y_i{c )-})^2{c )-}){c )-}
. * look at slide 65
. 
. gen sqerror        = (EDUCBA - EDUCBA_hat)^2
{txt}
{com}. gen sqerror_probit = (EDUCBA - EDUCBA_probit_hat)^2
{txt}
{com}. 
. 
. qui summarize sqerror 
{txt}
{com}. di r(mean)^0.5
{res}.42860029
{txt}
{com}. 
. qui summarize sqerror_probit
{txt}
{com}. di r(mean)^0.5
{res}.42795955
{txt}
{com}. 
. * taking a random subsample *
. 
. 
. *Check https://www.stata.com/support/faqs/statistics/random-samples/ for the procedure
. 
. * In HA 1 you need to calculate RMSE for five random observations:
. 
. *We are going to take a random sub-sample. To make results replicable, I want 
. *to always make the exact same random draw. To achieve that, I will set a seed
. * so that the "random" number generator always begins with the same draw.
. 
. set seed 2024
{txt}
{com}. 
. *We make random draws from a uniform distribution (0,1) to assign to each 
. *observation
. generate rand_draw = runiform()
{txt}
{com}. 
. *We will sort our observations from smallest to largest and take the first "n"
. *. This is how I randomize our sample of size "n", in this case n=5. That is, 
. *I randomly assign the number one to some observations. 
. 
. sort rand_draw
{txt}
{com}. 
. // the first five observations are chosen to be in our subsample
. generate chosen = _n <= 5
{txt}
{com}. 
. browse rand_draw 
{txt}
{com}. 
. *Now we can call caluclate the rmse for the subsample of five observations
. 
. qui summarize sqerror if chosen==1
{txt}
{com}. di r(mean)^0.5
{res}.33685123
{txt}
{com}. 
. qui summarize sqerror_probit if chosen==1
{txt}
{com}. di r(mean)^0.5
{res}.32671098
{txt}
{com}. 
. 
. *----------------------------------------------------------------------------*
. *----------------------------------------------------------------------------*
. 
. log close // Close the log, end the file
      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\Users\mshams\Dropbox\Courses\are256b-w26\week2.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}15 Jan 2026, 16:51:50
{txt}{.-}
{smcl}
{txt}{sf}{ul off}